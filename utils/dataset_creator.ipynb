{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`flash-attn` is not available or the version is too old. Please install `flash-attn>=2.6.3`.\n",
      "`sageattention` is not available or the version is too old. Please install `sageattention>=2.1.1`.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import FluxKontextPipeline\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export HF_HUB_CACHE=./cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal FluxKontext Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:   0%|                                                 | 0/7 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:   0%|                                                      | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████| 3/3 [00:00<00:00, 29.36it/s]\u001b[A\n",
      "Loading pipeline components...:  29%|███████████▋                             | 2/7 [00:00<00:00,  5.39it/s]\n",
      "Loading checkpoint shards:   0%|                                                      | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Loading checkpoint shards:  50%|███████████████████████                       | 1/2 [00:00<00:00,  6.99it/s]\u001b[A\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████| 2/2 [00:00<00:00,  7.01it/s]\u001b[A\n",
      "Loading pipeline components...:  57%|███████████████████████▍                 | 4/7 [00:00<00:00,  5.46it/s]You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "Loading pipeline components...: 100%|█████████████████████████████████████████| 7/7 [00:00<00:00,  7.14it/s]\n"
     ]
    }
   ],
   "source": [
    "pipe = FluxKontextPipeline.from_pretrained(\n",
    "    \"black-forest-labs/FLUX.1-Kontext-dev\", torch_dtype=torch.bfloat16\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the subject/character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 14/14 [00:17<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_image(base_scene_path, save_path, prompt = \"Add character to the image.\", width=None, height=None):\n",
    "    base_scene = Image.open(base_scene_path).convert(\"RGB\")\n",
    "\n",
    "    if width is None:\n",
    "        width, height = base_scene.size\n",
    "\n",
    "    seed = torch.Generator().manual_seed(42)\n",
    "\n",
    "    result_img_base = pipe(\n",
    "        prompt=prompt,\n",
    "        image=base_scene,\n",
    "        num_inference_steps=28,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        # generator=seed,\n",
    "        _auto_resize=False\n",
    "    ).images[0]\n",
    "    result_img_base.save(save_path)\n",
    "    return result_img_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"custom_data\"\n",
    "\n",
    "end_dir = os.path.join(src, \"end\")\n",
    "image_extensions = (\".png\", \".jpg\", \".jpeg\", \".webp\")\n",
    "image_paths = [\n",
    "    os.path.join(end_dir, fname)\n",
    "    for fname in os.listdir(end_dir)\n",
    "    if fname.lower().endswith(image_extensions)\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_prompt = \"Extract the boy from the image, in a white background.\"\n",
    "for image_path in image_paths:\n",
    "    reference_save_path = image_path.replace(\"end\", \"reference\")\n",
    "    generate_image(image_path, reference_save_path, reference_prompt, 512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_prompt = \"Remove the boy from the image.\"\n",
    "for image_path in image_paths:\n",
    "    start_save_path = image_path.replace(\"end\", \"start\")\n",
    "    generate_image(image_path, start_save_path, start_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
